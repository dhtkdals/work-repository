# 2주차 데이터 정제&시각화


### 1. 필수 라이브러리 설치

프로젝트를 실행하기 전에 다음과 같은 파이썬 라이브러리를 설치해야 함:

- `requests`: 웹페이지 요청을 보내기 위한 라이브러리.
- `BeautifulSoup`: HTML 파싱을 위한 라이브러리.
- `konlpy`: 한국어 텍스트 처리를 위한 라이브러리.
- `matplotlib`: 시각화를 위한 라이브러리.
- `wordcloud`: 워드 클라우드 생성을 위한 라이브러리.

#2. 코드의 전반적인 틀
코드를 실행하면 사용자로부터 검색 키워드를 입력받은뒤,  Daum 뉴스 홈페이지에서 해당 키워드와 관련된 뉴스 기사를 크롤링함.
그 후 뉴스 기사들에서 키워드와 관련된 단어들을 추출하여 워드 클라우드로 시각화함

4. 크롤링 및 워드 클라우드 생성
크롤링된 텍스트 데이터는 정제, 한국어 텍스트 데이터만 남도록 처리
텍스트는 단어 단위로 토큰화되며, 일반적인 불용어는 제거.
단어의 빈도수를 계산하고, 워드 클라우드를 생성함.
생성된 워드 클라우드는 시각화되어 출력됨.




코드 설명
1. crawl_daum_news_home(url, keyword=None)
python
Copy code
# Daum 뉴스 크롤링 함수
def crawl_daum_news_home(url, keyword=None):
    # 코드 내용
이 함수는 Daum 뉴스 홈페이지에서 뉴스 기사 제목과 링크를 크롤링하는 함수 이 함수는 원하는 키워드로 뉴스를 필터링할 수 있음.

2. tokenize_text(text)
python
Copy code
# Konlpy Okt를 사용하여 텍스트 토큰화
def tokenize_text(text):
    # 코드 내용
이 함수는 한국어 텍스트를 토큰화하는 함수로, Konlpy 라이브러리의 Okt를 사용함. 이 과정은 텍스트를 의미 있는 단어로 분해함.

3. remove_stopwords(tokens)
python
Copy code
# 불용어 제거
def remove_stopwords(tokens):
    # 코드 내용
이 함수는 토큰에서 불용어를 제거하는 함수임. 이로써 분석에 불필요한 단어가 제거됨.

4. main()
python
Copy code
# 메인 함수
def main():
    # 코드 내용
이 함수는 코드의 메인 함수로, 사용자로부터 검색 키워드를 입력받고 전체 프로세스를 실행됨.

5. 워드 클라우드 생성 및 시각화
워드 클라우드 생성 후, 결과가 시각화되어 출력됨.

# 아쉬운점(오래 걸렸던 점)
원활한 실행을 위해 사전 작업을 해야함(ex. java 설치, 폰트 등등)
워드 클라우드 생성을 위해 한글 폰트가 필요하며, 폰트 적용에서 애를 먹음

